{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2876ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic Model for GSAi Prompt and Response Data using data from 3/14-3/31\n",
    "# Purpose: Build a topic model that will help us uncover topics in both user prompts and assistant responses that may have been missed in the AI safety teams topic log\n",
    "# MOD: This is a Convo version meaning the user and assistant prompts are consolidated by the ID\n",
    "# MOD: This also applies bigram/trigram function to topic model\n",
    "# Using only LDAvis, 10 topics \n",
    "# Author: Kai Cobb\n",
    "# Last updated: 04/07/2025 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576d22f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install pandas numpy spacy nltk sentence-transformers bertopic gensim pyLDAvis scikit-learn\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import nltk\n",
    "import json\n",
    "import gensim\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora import Dictionary\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from nltk.util import ngrams\n",
    "import datetime\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load English NLP model for lemmatization\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# Load stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "#IMPORT TQDM FOR RUNNING PROGRESS#\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a9ee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################\n",
    "# ---- Step 1:Load the Data ---- #\n",
    "##################################\n",
    "\n",
    "# Load prompts dataset (replace with actual file path if needed)\n",
    "#Import the dataset#\n",
    "\n",
    "df= pd.read_excel(r\"D:\\Users\\kaiecobb\\Documents\\GitHub\\NLP4Survey\\Customer-Data-Survey-Analysis\\Notebooks\\GSAi Topic Model\\MSG-P-AI-datadog-20250403.xlsx\")\n",
    "\n",
    "type(df)\n",
    "\n",
    "# Overview of dataset \n",
    "print(df.info()) # Check column types and missing values\n",
    "print(df.describe()) # Summary Statistics\n",
    "\n",
    "#Preview first few rows\n",
    "df.head()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8294825d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.rename(columns={'content': 'prompt'}, inplace=True)\n",
    "# Concatenate use and assistent content in conversation order: \n",
    "# Group by conversation ID, sort by timestamp\n",
    "df = df.sort_values(by=[\"id\", \"timestamp\"])\n",
    "\n",
    "# Group by Id and concatenate user + assistant messages\n",
    "convo_df = df.groupby(\"id\")[\"prompt\"].apply(lambda x: \" \".join(x.astype(str))).reset_index()\n",
    "\n",
    "convo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1162c236",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "# ---- Step 2: EDA and Pre-processing ---- #\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339c38b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and Preprocess Text (LDA & BERTopic Compatible)\n",
    "def preprocess_text(text):\n",
    "    \"\"\"preprocess text for both BERT and LDA.\"\"\"\n",
    "    if pd.isnull(text): # Handle missing values\n",
    "        return \"\"\n",
    "    \n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'\\s+', ' ', text) # Remove extra whitespace\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove punctuation & numbers\n",
    "\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in nlp(text) if token.text not in stop_words and len(token.text) > 2] # Lemmatization and stopword removal\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# apply preprocess function\n",
    "convo_df[\"cleaned_prompts\"] = convo_df[\"prompt\"].astype(str).apply(preprocess_text)\n",
    "\n",
    "# Remove empty rows\n",
    "convo_df = convo_df[convo_df[\"cleaned_prompts\"].str.strip() !=\"\"]\n",
    "\n",
    "# Remove duplicates\n",
    "convo_df = convo_df.drop_duplicates(subset=[\"cleaned_prompts\"])\n",
    "\n",
    "# Check cleaned prompts\n",
    "convo_df[\"cleaned_prompts\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21941334",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Word Frequency Analysis\n",
    "\n",
    "# Tokenize cleaned text\n",
    "all_words = \" \".join(convo_df[\"cleaned_prompts\"]).split()\n",
    "word_freq = Counter(all_words)\n",
    "\n",
    "# Most common words\n",
    "print(word_freq.most_common(20))\n",
    "\n",
    "# Word Cloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color=\"white\").generate(\" \".join(all_words))\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319cc23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Bi-gram & Tri-gram Analysis\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "# Function to generate n-grams\n",
    "def get_ngrams(texts, n=2, top_n=20):\n",
    "    ngram_list = []\n",
    "    for text in texts:\n",
    "        tokens = text.split()\n",
    "        ngram_list.extend(list(ngrams(tokens, n)))\n",
    "    return Counter(ngram_list).most_common(top_n)\n",
    "\n",
    "\n",
    "# Show top bi-grams & tri-grams\n",
    "print(\"Top Bigrams:\", get_ngrams(convo_df[\"cleaned_prompts\"], 2))\n",
    "print(\"Top Trigrams:\", get_ngrams(convo_df[\"cleaned_prompts\"], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7acc02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Anomalies after Cleaning\n",
    "# Make sure dataset is clean before modeling\n",
    "\n",
    "# Check missing values\n",
    "print(convo_df.isnull().sum())\n",
    "\n",
    "# Check duplicate prompts after cleaning\n",
    "print(\"Duplicates:\", convo_df.duplicated(subset=[\"cleaned_prompts\"]).sum())\n",
    "\n",
    "# Check text length distribution\n",
    "convo_df[\"text_length\"] = convo_df[\"cleaned_prompts\"].apply(lambda x: len(x.split()))\n",
    "convo_df[\"text_length\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e08c074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting Processed Text for LDAvis\n",
    "\n",
    "\n",
    "def generate_bigrams_trigrams(texts, min_count=5, threshold=10):\n",
    "    \"\"\"\n",
    "    Apply bigrams and trigrams to tokenized texts.\n",
    "    \"\"\"\n",
    "    tokenized_texts = [text.split() for text in texts]\n",
    "\n",
    "    # Build the bigram and trigram models\n",
    "    bigram = Phrases(tokenized_texts, min_count=min_count, threshold=threshold)\n",
    "    trigram = Phrases(bigram[tokenized_texts], threshold=threshold)\n",
    "\n",
    "    bigram_mod = Phraser(bigram)\n",
    "    trigram_mod = Phraser(trigram)\n",
    "\n",
    "    # Apply the models\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in tokenized_texts]\n",
    "\n",
    "#Tokenize   \n",
    "tokenized_texts = generate_bigrams_trigrams(convo_df[\"cleaned_prompts\"])\n",
    "   \n",
    "# Create dicitonary \n",
    "dictionary = Dictionary(tokenized_texts)\n",
    "\n",
    "# Filter extremes \n",
    "dictionary.filter_extremes(no_below=5, no_above=0.7)\n",
    "\n",
    "# Convert to corpus\n",
    "corpus = [dictionary.doc2bow(text) for text in tokenized_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f148e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate and save an EDA report\n",
    "\n",
    "\n",
    "def generate_eda_report(convo_df, text_column=\"cleaned_prompts\", output_path=\"eda_report_GSAi_Topic_Model_10_Topics_Convo_v2.json\"):\n",
    "    report = {}\n",
    "\n",
    "    # Dataset Overview\n",
    "    report[\"Dataset Summary\"] = {\n",
    "        \"Total Rows\": int(len(convo_df)),\n",
    "        \"Missing Values\": int(convo_df[text_column].isnull().sum()),\n",
    "        \"Duplicate Entries\": int(convo_df.duplicated(subset=[text_column]).sum()),\n",
    "        \"Average Text Length\": float(convo_df[text_column].apply(lambda x: len(x.split())).mean()),\n",
    "        \"Min Text Length\": int(convo_df[text_column].apply(lambda x: len(x.split())).min()),\n",
    "        \"Max Text Length\": int(convo_df[text_column].apply(lambda x: len(x.split())).max()),\n",
    "    }\n",
    "\n",
    "    # Word Frequency Analysis\n",
    "    all_words = \" \".join(convo_df[text_column]).split()\n",
    "    word_freq = Counter(all_words)\n",
    "    report[\"Top Words\"] = [(word, int(freq)) for word, freq in word_freq.most_common(20)]\n",
    "\n",
    "    # N-gram Analysis\n",
    "    report[\"Top Bigrams\"] = [(str(ngram), int(freq)) for ngram, freq in get_ngrams(convo_df[text_column], 2)]\n",
    "    report[\"Top Trigrams\"] = [(str(ngram), int(freq)) for ngram, freq in get_ngrams(convo_df[text_column], 3)]\n",
    "\n",
    "\n",
    "    # Save report as JSON\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(report, f, indent=4)\n",
    "\n",
    "    print(f\"EDA report saved to {output_path}\")\n",
    "\n",
    "# Run EDA and save results\n",
    "generate_eda_report(convo_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1294ca18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#################################\n",
    "# ---- Step 3: Topic Model ---- #\n",
    "#################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458de6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define a Logging Function for tracking LDAvis and BERTopic results\n",
    "import datetime\n",
    "\n",
    "def log_results(model_name, parameters, topics, coherence_score, output_path=\"model_results__GSAi_Topic_Model_10_Topics_Convo_v2.json\"):\n",
    "    \"\"\"Logs model parameters and results.\"\"\"\n",
    "    log_entry = {\n",
    "        \"timestamp\": str(datetime.datetime.now()),\n",
    "        \"model\": model_name,\n",
    "        \"parameters\": parameters,\n",
    "        \"topics\": topics,\n",
    "        \"coherence_score\": coherence_score,\n",
    "    }\n",
    "\n",
    "    # Load existing results if file exists\n",
    "    try:\n",
    "        with open(output_path, \"r\") as f:\n",
    "            logs = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        logs = []\n",
    "\n",
    "    logs.append(log_entry)\n",
    "\n",
    "    # Save updated results\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(logs, f, indent=4)\n",
    "\n",
    "    print(f\"Results logged to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839e7ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###################\n",
    "# LDA Topic Model #\n",
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2735970",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from itertools import product\n",
    "\n",
    "# Function to train and evaluate LDA with different parameters\n",
    "def tune_lda(dictionary, corpus, texts, num_topics_list, alpha_list, beta_list):\n",
    "    best_model = None\n",
    "    best_coherence = 0\n",
    "    results = []\n",
    "\n",
    "    # Create a list of all parameter combinations\n",
    "    param_combinations = list(product(num_topics_list, alpha_list, beta_list))\n",
    "\n",
    "\n",
    "    # Wrap the param combinations in tqdm\n",
    "    for num_topics, alpha, beta in tqdm(param_combinations, desc=\"Tuning LDA Models\", ncols=100):\n",
    "        lda_model = LdaModel(\n",
    "            corpus=corpus,\n",
    "            id2word=dictionary,\n",
    "            num_topics=num_topics,\n",
    "            random_state=42,\n",
    "            update_every=1,\n",
    "            chunksize=100,\n",
    "            passes=10,\n",
    "            alpha=alpha,\n",
    "            eta=beta\n",
    "        )\n",
    "\n",
    "        # Compute Coherence Score\n",
    "        coherence_model_lda = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_score = coherence_model_lda.get_coherence()\n",
    "\n",
    "        tqdm.write(f\"Topics={num_topics}, Alpha={alpha}, Beta={beta}, Coherence={coherence_score:.4f}\")\n",
    "\n",
    "        results.append((num_topics, alpha, beta, coherence_score))\n",
    "\n",
    "        # Track best model\n",
    "        if coherence_score > best_coherence:\n",
    "                best_model = lda_model\n",
    "                best_coherence = coherence_score\n",
    "\n",
    "    return best_model, results\n",
    "\n",
    "# Define parameter search space\n",
    "num_topics_list = [10]   # 10 as the intended number of topics\n",
    "alpha_list = ['symmetric', 'asymmetric', 0.01, 0.1, 0.5]  # Test different alpha values\n",
    "beta_list = ['symmetric', 0.01, 0.1, 0.5]  # Test different beta values\n",
    "\n",
    "# Run LDA tuning\n",
    "best_lda, lda_results = tune_lda(dictionary, corpus, tokenized_texts, num_topics_list, alpha_list, beta_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fe6b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record and Analyze Results\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "lda_results_df = pd.DataFrame(lda_results, columns=[\"Num Topics\", \"Alpha\", \"Beta\", \"Coherence Score\"])\n",
    "\n",
    "# Sort by best coherence score\n",
    "lda_results_df = lda_results_df.sort_values(by=\"Coherence Score\", ascending=False)\n",
    "\n",
    "# Display top 5 results\n",
    "print(lda_results_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae039c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#save lda model\n",
    "best_lda.save(\"best_lda_model__GSAi_Topic_Model_10_Topics_Convo_v2.model\")\n",
    "\n",
    "#save dicitonary\n",
    "dictionary.save(\"lda_dictionary.dict\")\n",
    "\n",
    "#save corpus\n",
    "gensim.corpora.MmCorpus.serialize(\"lda_corpus.mm\", corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca7b6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "########################################\n",
    "### LDAvis Topic Model Visualization ###\n",
    "########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fbbda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "# Prepare the LDA visualization based off of best LDA model with num_topics=10, alpha='0.5', and beta=0.5\n",
    "lda_display = gensimvis.prepare(best_lda, corpus, dictionary, sort_topics=False)\n",
    "\n",
    "# Show LDA visualization\n",
    "pyLDAvis.display(lda_display)\n",
    "\n",
    "pyLDAvis.save_html(lda_display, \"lda_topics_visualization__GSAi_Topic_Model_10_Topics_Convo_v2.html\")\n",
    "print(\"LDAvis HTML saved. Open 'lda_topics_visualization__GSAi_Topic_Model_10_Topics_Convo_v2.html' to explore topics.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6d0eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get topic distributions for each document\n",
    "doc_topics = best_lda.get_document_topics(corpus, minimum_probability=0)\n",
    "\n",
    "# Convert to a DataFrame\n",
    "topic_matrix = pd.DataFrame([[tup[1] for tup in doc] for doc in doc_topics])\n",
    "\n",
    "# Rename columns to \"Topic_0\", \"Topic_1\", ..., \"Topic_N\"\n",
    "topic_matrix.columns = [f'Topic_{i}' for i in range(best_lda.num_topics)]\n",
    "\n",
    "# Add Document ID (if available)\n",
    "topic_matrix['Document_ID'] = range(len(topic_matrix))\n",
    "\n",
    "# Check the output\n",
    "print(topic_matrix.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2668f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign most dominant topic\n",
    "topic_matrix['Dominant_Topic'] = topic_matrix.iloc[:, :-1].idxmax(axis=1)\n",
    "\n",
    "# Convert \"Topic_0\" → 0, \"Topic_1\" → 1, etc.\n",
    "topic_matrix['Dominant_Topic'] = topic_matrix['Dominant_Topic'].apply(lambda x: int(x.split('_')[1]))\n",
    "\n",
    "print(topic_matrix[['Document_ID', 'Dominant_Topic']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c74dacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top words for each topic\n",
    "topic_words = {i: [word for word, _ in best_lda.show_topic(i, topn=10)] for i in range(best_lda.num_topics)}\n",
    "\n",
    "# Convert to DataFrame\n",
    "topic_word_df = pd.DataFrame.from_dict(topic_words, orient='index', columns=[f'Word_{i}' for i in range(10)])\n",
    "\n",
    "print(topic_word_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e85d21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_matrix.to_csv(\"document_topic_matrix__GSAi_Topic_Model_10_Topics_Convo_v2.csv\", index=False)\n",
    "topic_word_df.to_csv(\"topic_word_distribution__GSAi_Topic_Model_10_Topics_Convo_v2.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d445e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the dominant topic for each document\n",
    "topics_per_doc = [max(best_lda[doc], key=lambda x: x[1])[0] for doc in corpus]\n",
    "\n",
    "# Count the occurrences of each topic\n",
    "from collections import Counter\n",
    "topic_counts = Counter(topics_per_doc)\n",
    "\n",
    "# Print topic distribution\n",
    "for topic_id, count in sorted(topic_counts.items()):\n",
    "    print(f\"Topic {topic_id}: {count} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b54ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Merge main df and topic_df\n",
    "# Ensure main_df has a Document_ID column\n",
    "main_df = convo_df.reset_index().rename(columns={\"index\": \"Document_ID\"})\n",
    "\n",
    "# Merge main_df with topic_df\n",
    "merged_df = main_df.merge(topic_matrix, on=\"Document_ID\", how=\"left\")\n",
    "\n",
    "# Check the first few rows\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af9b4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "merged_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc4bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
