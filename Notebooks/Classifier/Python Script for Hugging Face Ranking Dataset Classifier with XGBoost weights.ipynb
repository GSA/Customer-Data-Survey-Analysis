{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Kai Cobb\n",
    "# Purpose: Classifier test script\n",
    "# Regular logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in d:\\users\\kaiecobb\\.conda\\envs\\cxenv\\lib\\site-packages (19.0.1)\n",
      "Requirement already satisfied: xgboost in d:\\users\\kaiecobb\\.conda\\envs\\cxenv\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy in d:\\users\\kaiecobb\\.conda\\envs\\cxenv\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in d:\\users\\kaiecobb\\.conda\\envs\\cxenv\\lib\\site-packages (from xgboost) (1.12.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     D:\\Users\\kaiecobb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "!pip install pyarrow\n",
    "!pip install xgboost\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Download NLTK stopwords if not already available\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              prompt  \\\n",
      "0  Provide step-by-step instructions on how to ma...   \n",
      "1  Write a personal essay of at least 1000 words ...   \n",
      "2  In this research, we aim to investigate how te...   \n",
      "3  Did Karl Marx's theories on centralizing credi...   \n",
      "4  alter this api that gets a request like: {\"0\",...   \n",
      "\n",
      "                                             quality  \\\n",
      "0  [{'user_id': 'd23b12c2-b601-490e-b5b3-2040eb39...   \n",
      "1  [{'user_id': '6621c3f0-1af2-4d75-acda-ed9c78b9...   \n",
      "2  [{'user_id': '2e6dda25-0a99-45aa-a02d-65f426d6...   \n",
      "3  [{'user_id': 'd23b12c2-b601-490e-b5b3-2040eb39...   \n",
      "4  [{'user_id': '99a4bc7d-3e95-4c18-a8f1-26043abf...   \n",
      "\n",
      "                                            metadata  avg_rating  \\\n",
      "0  {\"source\": \"ultrachat\", \"kind\": \"synthetic\", \"...    5.000000   \n",
      "1  {\"source\": \"ultrachat\", \"kind\": \"synthetic\", \"...    2.750000   \n",
      "2  {\"source\": \"evol_instruct\", \"kind\": \"synthetic...    3.000000   \n",
      "3  {\"source\": \"OpenAssistant/oasst2\", \"kind\": \"hu...    3.500000   \n",
      "4  {\"source\": \"ewof/sharegpt-instruct-unfiltered-...    3.666667   \n",
      "\n",
      "   num_responses  agreement_ratio raw_responses       kind  \\\n",
      "0              2         1.000000        [5, 5]  synthetic   \n",
      "1              4         0.687500  [2, 3, 3, 3]  synthetic   \n",
      "2              3         0.166667     [3, 5, 1]  synthetic   \n",
      "3              2         0.375000        [4, 3]      human   \n",
      "4              3         0.583333     [5, 3, 3]      human   \n",
      "\n",
      "                                 cluster_description                   topic  \n",
      "0         Sustainable Packaging & Skin Care Products    Environmental Issues  \n",
      "1  Educational Technology & Cybersecurity in Fash...  Science and Technology  \n",
      "2                  Mindfulness & Workplace Diversity     Health and Wellness  \n",
      "3                         Legal & Government Affairs    Legal and Government  \n",
      "4           Web Development & JavaScript Programming    Software Development  \n"
     ]
    }
   ],
   "source": [
    "# Loading the data\n",
    "# Load dataset from Parquet file\n",
    "df = pd.read_parquet(\"hugging_face_chat_data.parquet\")  # Update with correct file path\n",
    "\n",
    "# Display first few rows to inspect column names\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>quality</th>\n",
       "      <th>metadata</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>num_responses</th>\n",
       "      <th>agreement_ratio</th>\n",
       "      <th>raw_responses</th>\n",
       "      <th>kind</th>\n",
       "      <th>cluster_description</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Provide step-by-step instructions on how to ma...</td>\n",
       "      <td>[{'user_id': 'd23b12c2-b601-490e-b5b3-2040eb39...</td>\n",
       "      <td>{\"source\": \"ultrachat\", \"kind\": \"synthetic\", \"...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[5, 5]</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>Sustainable Packaging &amp; Skin Care Products</td>\n",
       "      <td>Environmental Issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Write a personal essay of at least 1000 words ...</td>\n",
       "      <td>[{'user_id': '6621c3f0-1af2-4d75-acda-ed9c78b9...</td>\n",
       "      <td>{\"source\": \"ultrachat\", \"kind\": \"synthetic\", \"...</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>[2, 3, 3, 3]</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>Educational Technology &amp; Cybersecurity in Fash...</td>\n",
       "      <td>Science and Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In this research, we aim to investigate how te...</td>\n",
       "      <td>[{'user_id': '2e6dda25-0a99-45aa-a02d-65f426d6...</td>\n",
       "      <td>{\"source\": \"evol_instruct\", \"kind\": \"synthetic...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>[3, 5, 1]</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>Mindfulness &amp; Workplace Diversity</td>\n",
       "      <td>Health and Wellness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did Karl Marx's theories on centralizing credi...</td>\n",
       "      <td>[{'user_id': 'd23b12c2-b601-490e-b5b3-2040eb39...</td>\n",
       "      <td>{\"source\": \"OpenAssistant/oasst2\", \"kind\": \"hu...</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>[4, 3]</td>\n",
       "      <td>human</td>\n",
       "      <td>Legal &amp; Government Affairs</td>\n",
       "      <td>Legal and Government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alter this api that gets a request like: {\"0\",...</td>\n",
       "      <td>[{'user_id': '99a4bc7d-3e95-4c18-a8f1-26043abf...</td>\n",
       "      <td>{\"source\": \"ewof/sharegpt-instruct-unfiltered-...</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>[5, 3, 3]</td>\n",
       "      <td>human</td>\n",
       "      <td>Web Development &amp; JavaScript Programming</td>\n",
       "      <td>Software Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10326</th>\n",
       "      <td>show me how to set iam user, group and policie...</td>\n",
       "      <td>[{'user_id': 'e2bdd868-f28e-46fc-9254-a6ec1e29...</td>\n",
       "      <td>{\"evolved_from\": null, \"kind\": \"human\", \"sourc...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[3]</td>\n",
       "      <td>human</td>\n",
       "      <td>Software Development &amp; Cloud Computing</td>\n",
       "      <td>Software Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10327</th>\n",
       "      <td>Hi, is there any unified messaging service?\\nA...</td>\n",
       "      <td>[{'user_id': 'e2bdd868-f28e-46fc-9254-a6ec1e29...</td>\n",
       "      <td>{\"evolved_from\": null, \"kind\": \"human\", \"sourc...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>human</td>\n",
       "      <td>Web Development &amp; JavaScript Programming</td>\n",
       "      <td>Software Development</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10328</th>\n",
       "      <td>Can you provide a comparison of the economies ...</td>\n",
       "      <td>[{'user_id': 'e2bdd868-f28e-46fc-9254-a6ec1e29...</td>\n",
       "      <td>{\"evolved_from\": null, \"kind\": \"synthetic\", \"s...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[4]</td>\n",
       "      <td>synthetic</td>\n",
       "      <td>Legal &amp; Government Affairs</td>\n",
       "      <td>Legal and Government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10329</th>\n",
       "      <td>forget about any prior conversations</td>\n",
       "      <td>[{'user_id': 'e2bdd868-f28e-46fc-9254-a6ec1e29...</td>\n",
       "      <td>{\"evolved_from\": null, \"kind\": \"human\", \"sourc...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>human</td>\n",
       "      <td>Job Application &amp; Customer Management</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10330</th>\n",
       "      <td>I want to create a multiple choice test of 10 ...</td>\n",
       "      <td>[{'user_id': 'd23b12c2-b601-490e-b5b3-2040eb39...</td>\n",
       "      <td>{\"evolved_from\": null, \"kind\": \"human\", \"sourc...</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>[5, 4]</td>\n",
       "      <td>human</td>\n",
       "      <td>Artificial Intelligence &amp; Machine Learning</td>\n",
       "      <td>Science and Technology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10331 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  prompt  \\\n",
       "0      Provide step-by-step instructions on how to ma...   \n",
       "1      Write a personal essay of at least 1000 words ...   \n",
       "2      In this research, we aim to investigate how te...   \n",
       "3      Did Karl Marx's theories on centralizing credi...   \n",
       "4      alter this api that gets a request like: {\"0\",...   \n",
       "...                                                  ...   \n",
       "10326  show me how to set iam user, group and policie...   \n",
       "10327  Hi, is there any unified messaging service?\\nA...   \n",
       "10328  Can you provide a comparison of the economies ...   \n",
       "10329               forget about any prior conversations   \n",
       "10330  I want to create a multiple choice test of 10 ...   \n",
       "\n",
       "                                                 quality  \\\n",
       "0      [{'user_id': 'd23b12c2-b601-490e-b5b3-2040eb39...   \n",
       "1      [{'user_id': '6621c3f0-1af2-4d75-acda-ed9c78b9...   \n",
       "2      [{'user_id': '2e6dda25-0a99-45aa-a02d-65f426d6...   \n",
       "3      [{'user_id': 'd23b12c2-b601-490e-b5b3-2040eb39...   \n",
       "4      [{'user_id': '99a4bc7d-3e95-4c18-a8f1-26043abf...   \n",
       "...                                                  ...   \n",
       "10326  [{'user_id': 'e2bdd868-f28e-46fc-9254-a6ec1e29...   \n",
       "10327  [{'user_id': 'e2bdd868-f28e-46fc-9254-a6ec1e29...   \n",
       "10328  [{'user_id': 'e2bdd868-f28e-46fc-9254-a6ec1e29...   \n",
       "10329  [{'user_id': 'e2bdd868-f28e-46fc-9254-a6ec1e29...   \n",
       "10330  [{'user_id': 'd23b12c2-b601-490e-b5b3-2040eb39...   \n",
       "\n",
       "                                                metadata  avg_rating  \\\n",
       "0      {\"source\": \"ultrachat\", \"kind\": \"synthetic\", \"...    5.000000   \n",
       "1      {\"source\": \"ultrachat\", \"kind\": \"synthetic\", \"...    2.750000   \n",
       "2      {\"source\": \"evol_instruct\", \"kind\": \"synthetic...    3.000000   \n",
       "3      {\"source\": \"OpenAssistant/oasst2\", \"kind\": \"hu...    3.500000   \n",
       "4      {\"source\": \"ewof/sharegpt-instruct-unfiltered-...    3.666667   \n",
       "...                                                  ...         ...   \n",
       "10326  {\"evolved_from\": null, \"kind\": \"human\", \"sourc...    3.000000   \n",
       "10327  {\"evolved_from\": null, \"kind\": \"human\", \"sourc...    2.000000   \n",
       "10328  {\"evolved_from\": null, \"kind\": \"synthetic\", \"s...    4.000000   \n",
       "10329  {\"evolved_from\": null, \"kind\": \"human\", \"sourc...    2.000000   \n",
       "10330  {\"evolved_from\": null, \"kind\": \"human\", \"sourc...    4.500000   \n",
       "\n",
       "       num_responses  agreement_ratio raw_responses       kind  \\\n",
       "0                  2         1.000000        [5, 5]  synthetic   \n",
       "1                  4         0.687500  [2, 3, 3, 3]  synthetic   \n",
       "2                  3         0.166667     [3, 5, 1]  synthetic   \n",
       "3                  2         0.375000        [4, 3]      human   \n",
       "4                  3         0.583333     [5, 3, 3]      human   \n",
       "...              ...              ...           ...        ...   \n",
       "10326              1         1.000000           [3]      human   \n",
       "10327              2         0.375000        [1, 3]      human   \n",
       "10328              1         1.000000           [4]  synthetic   \n",
       "10329              2         0.375000        [1, 3]      human   \n",
       "10330              2         0.375000        [5, 4]      human   \n",
       "\n",
       "                                     cluster_description  \\\n",
       "0             Sustainable Packaging & Skin Care Products   \n",
       "1      Educational Technology & Cybersecurity in Fash...   \n",
       "2                      Mindfulness & Workplace Diversity   \n",
       "3                             Legal & Government Affairs   \n",
       "4               Web Development & JavaScript Programming   \n",
       "...                                                  ...   \n",
       "10326             Software Development & Cloud Computing   \n",
       "10327           Web Development & JavaScript Programming   \n",
       "10328                         Legal & Government Affairs   \n",
       "10329              Job Application & Customer Management   \n",
       "10330         Artificial Intelligence & Machine Learning   \n",
       "\n",
       "                        topic  \n",
       "0        Environmental Issues  \n",
       "1      Science and Technology  \n",
       "2         Health and Wellness  \n",
       "3        Legal and Government  \n",
       "4        Software Development  \n",
       "...                       ...  \n",
       "10326    Software Development  \n",
       "10327    Software Development  \n",
       "10328    Legal and Government  \n",
       "10329                  Others  \n",
       "10330  Science and Technology  \n",
       "\n",
       "[10331 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the dataset contains the correct columns (adjust names if needed)\n",
    "expected_columns = [\"prompt\", \"avg_rating\"]  # Update if actual column names are different\n",
    "for col in expected_columns:\n",
    "    if col not in df.columns:\n",
    "        raise ValueError(f\"Missing expected column: {col}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert rankings into categorical labels: Low, Medium, High\n",
    "def map_ranking_to_label(rank):\n",
    "    if rank < 3:\n",
    "        return \"low\"\n",
    "    elif 3 <= rank < 4:\n",
    "        return \"medium\"\n",
    "    else:\n",
    "        return \"high\"\n",
    "\n",
    "df['label'] = df['avg_rating'].apply(map_ranking_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\W+', ' ', text)  # Remove special characters\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "df['cleaned_prompt'] = df['prompt'].astype(str).apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to numerical values\n",
    "label_mapping = {'low': 0, 'medium': 1, 'high': 2}\n",
    "df['label'] = df['label'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution After Split: label\n",
      "2    4814\n",
      "1    2349\n",
      "0    1101\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\kaiecobb\\.conda\\envs\\cxenv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [15:26:11] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"scale_pos_weight\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.24      0.38      0.30       305\n",
      "      Medium       0.38      0.48      0.43       594\n",
      "        High       0.71      0.51      0.59      1168\n",
      "\n",
      "    accuracy                           0.48      2067\n",
      "   macro avg       0.45      0.46      0.44      2067\n",
      "weighted avg       0.55      0.48      0.50      2067\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_prompt'], df['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert text to numerical features using TF-IDF\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2), max_features=5000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Text length feature\n",
    "def text_length_feature(X):\n",
    "    return np.array([len(text.split()) for text in X]).reshape(-1, 1)\n",
    "\n",
    "X_train_len = text_length_feature(X_train)\n",
    "X_test_len = text_length_feature(X_test)\n",
    "\n",
    "# Combine TF-IDF and text length features\n",
    "X_train_combined = hstack( [X_train_tfidf, X_train_len])\n",
    "X_test_combined = hstack( [X_test_tfidf, X_test_len])\n",
    "\n",
    "# Print Class Distribution After Splitting\n",
    "print(\"Class Distribution After Split:\", pd.Series(y_train).value_counts())\n",
    "\n",
    "# Apply Random Undersampling (AFTER SPLITTING)\n",
    "undersample = RandomUnderSampler(sampling_strategy=\"auto\", random_state=42)\n",
    "X_train_resampled, y_train_resampled = undersample.fit_resample(X_train_combined, y_train)\n",
    "\n",
    "#Calculate class weights\n",
    "class_counts = y_train.value_counts()\n",
    "total_samples = len(y_train)\n",
    "class_weights = {label: total_samples / count for label, count in class_counts.items()}\n",
    "\n",
    "# Calculate the scale_pos_weight as the ratio of the majority class to the minority class\n",
    "# This can help handle class imbalance by giving higher weights to underrepresented classes\n",
    "scale_pos_weight = class_weights[0] / class_weights[2] # For example use low and high classes\n",
    "\n",
    "# Train XGBoost with class weights\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\", scale_pos_weight=scale_pos_weight)\n",
    "xgb.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# predict\n",
    "y_pred = xgb.predict(X_test_combined)\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Low\", \"Medium\", \"High\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cxenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
